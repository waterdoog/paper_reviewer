[
  {
    "id": "y9fN1DC4tT",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "decision": {
        "value": "Reject"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! We regret to inform you that your submission has not been accepted. Please see the reviews below for more information."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission229/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759950093186,
    "mdate": 1760632287073,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "vc8ZiYCkky",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper proposes DERP, a framework for enforcing latent distributional constraints in neural networks via random projections and a differentiable loss based on an 'average' Kolmogorov–Smirnov (KS) distance. While the idea is clearly presented and the paper is readable, the core contribution is incremental and closely related to existing methods such as Sliced Wasserstein Autoencoders, MMD-VAEs, and Adversarial Autoencoders. The equivalence of the proposed loss to the 1D Wasserstein-1 distance is not acknowledged, weakening the conceptual novelty. Experimental evaluation is limited by non-standard architectures, lack of multiple runs or error bars, insufficient baselines, and unclear reporting of key metrics (e.g., reconstruction quality, classifier protocol). Claims of minimal compute overhead are contradicted by the reported results. Important implementation details and related work are missing, and the empirical gains are modest and inconsistent. The paper would benefit from a more transparent positioning relative to prior work, stronger experimental rigor, and clearer theoretical analysis. Given these issues, I cannot recommend acceptance in its current form."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 2
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 2
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission229/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775852065,
    "mdate": 1760632203024,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "q04OcfDWVc",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Equation (4) is mathematically ill-defined: the normalization by ∫ dx on the real line diverges; integration limits/measure are unspecified (page 3).\n- No rigorous treatment of differentiability: empirical CDF-based losses are non-differentiable; no smoothing or differentiable surrogate is described (pages 3–4).\n- Conceptual error: posterior collapse is mischaracterized; high KL is labeled as collapse (Figure 2 caption, page 6; Table 1 vs Table 2 inconsistency).\n- Misuse of effect size: Cohen’s d is claimed to establish statistical significance without variance estimates or hypothesis tests (pages 5–6).\n- Active enforcement comparison is methodologically flawed: “Training KS” reported as 0 for baselines appears to indicate “not computed,” not a true metric; DERP’s Training KS values look constant and possibly placeholder (Tables 1 and 5, pages 5 and 7).\n- Insufficient justification for using only 3–5 random projections; no analysis of probe count vs statistical power (pages 3–4).\n- Classification accuracy and other metrics are under-specified (classifier type, training protocol, labels), limiting interpretability (pages 4–5).\n- Single-run results without error bars or hardware details; admitted in the checklist (page 12), undermining robustness claims.\n- Ambiguous definitions for activation rate and class separation ratios; computation of KS (one-sample vs two-sample; dataset vs batch) not clearly described.\n- Claims about computational overhead and power of the modified KS lack ablations and comparative baselines to standard tests."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776867811,
    "mdate": 1760640032167,
    "signatures": [
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "oSZsafjK96",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "desk_reject_comments": {
        "value": "Paper does not respect the conference requirements (e.g., Checklists and Formatting issues)"
      },
      "title": {
        "value": "Submission Desk Rejected by Program Chairs"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission229/-/Desk_Rejection",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Desk_Rejection",
    "cdate": 1758129471855,
    "mdate": 1765059672558,
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "j24USL1xKd",
    "forum": "j24USL1xKd",
    "content": {
      "title": {
        "value": "Distribution Enforcement via Random Probe: Active Distributional Constraints for Robust Deep Learning"
      },
      "keywords": {
        "value": [
          "variational autoencoders",
          "vae"
        ]
      },
      "abstract": {
        "value": "Deep learning models rely on distributional assumptions about latent representations, yet these assumptions are rarely explicitly enforced during training. We propose Distribution Enforcement via Random Probe (DERP), a framework that enforces distributional constraints through statistical testing integrated into backpropagation. Our approach explores whether explicit enforcement can improve distributional compliance compared to standard approaches that rely on emergent properties. We evaluate DERP on variational autoencoders using CIFAR-10 and CelebA datasets, showing improved distributional compliance in some cases (KS distance 0.037 vs 0.057 on CelebA) while demonstrating active distributional enforcement during training. DERP maintains computational efficiency with minimal overhead (0-4\\%), suggesting potential for broader applications in probabilistic machine learning. The implementation is open source and available for reproduction at https://github.com/belindamo/derp."
      },
      "pdf": {
        "value": "/pdf/1c27903206d64169041b4b775e3d1d504cee4b1f.pdf"
      },
      "venue": {
        "value": "Submitted to Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference/Rejected_Submission"
      },
      "_bibtex": {
        "value": "@misc{\nanonymous2025distribution,\ntitle={Distribution Enforcement via Random Probe: Active Distributional Constraints for Robust Deep Learning},\nauthor={Anonymous},\nyear={2025},\nurl={https://openreview.net/forum?id=j24USL1xKd}\n}"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/-/Desk_Rejected_Submission",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757959944433,
    "odate": 1758112145415,
    "mdate": 1765061647889,
    "signatures": [
      "Agents4Science/2025/Conference/Submission229/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission229/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "gqYRDi3y3o",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "The paper presents DERP, a framework for enforcing distributional constraints in VAEs via statistical testing. The idea is interesting and the use of random projections for differentiable statistical testing is novel. The paper is well-written, clearly structured, and addresses a real problem in probabilistic machine learning. However, there are significant concerns: the theoretical foundation is weak (no proofs for the modified Kolmogorov-Smirnov distance or convergence properties), experimental validation is limited (only two datasets, single runs, no statistical significance testing), and the improvements are modest. There is also a lack of comparison to existing posterior collapse prevention methods. While the approach is conceptually interesting and reasonably reproducible, the execution does not meet the standards for a top-tier venue. The work needs significant strengthening in theory and experimental rigor before acceptance."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission229/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775852487,
    "mdate": 1760632202727,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "NepKJj8ZuD",
    "forum": "j24USL1xKd",
    "replyto": "j24USL1xKd",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper introduces Distribution Enforcement via Random Probe (DERP), a novel framework for actively enforcing distributional assumptions in deep learning models, particularly Variational Autoencoders (VAEs). The core idea is to integrate a differentiable statistical test into the training loss, guiding the latent representations to conform to a target distribution. The method is motivated by the Cramér-Wold theorem and uses random 1D projections and a modified, differentiable Kolmogorov-Smirnov (KS) distance. The authors evaluate DERP on CIFAR-10 and CelebA, claiming it provides a better balance between distributional compliance and model performance compared to baselines.\n\nThe paper addresses an important problem and presents an original method. The writing is clear, and the authors are transparent about limitations. However, there are several major weaknesses:\n\n1. The core method (modified KS distance) lacks theoretical justification and statistical analysis. The formulation is ambiguous, and key terms are not well-defined or explained, making the loss term appear heuristic rather than principled.\n2. The experimental results are unconvincing and sometimes contradict the main claims. On CIFAR-10, DERP underperforms a baseline on the primary metric. On CelebA, a baseline achieves much higher classification accuracy despite worse distributional compliance, directly challenging the paper's premise. The paper fails to discuss this contradiction.\n3. The evaluation lacks statistical rigor: only single runs are reported, with no error bars, confidence intervals, or ablation studies. This undermines the reliability of the results.\n\nMinor weaknesses include missing experimental details (e.g., learning rates, optimizer parameters, batch sizes) and unclear figures.\n\nIn conclusion, while the research direction is creative and significant, the manuscript is not ready for publication. The method lacks theoretical grounding, and the experimental evidence is weak and inconsistent. The authors need to provide a rigorous justification for the core method, conduct more thorough and statistically sound experiments, and directly address contradictory results. Given these significant flaws, I recommend rejection."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 2
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 2
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission229/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775852283,
    "mdate": 1760632202864,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission229/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]