[
  {
    "id": "zmXrIIqa90",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nPlease look at your references to confirm they are good.\n\n**Examples of references that could not be verified (they might exist but the automated verification failed):**\n\n- Carbon-aware computing by A. Lottarini, N. K. Sharma, C. Stewart, and R. K. Sitaraman"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777962765,
    "mdate": 1760640224173,
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "w0WZjGlqOn",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper proposes energy-guided code generation, where LLM-generated programs are reranked based on direct energy measurements to select more energy-efficient implementations while maintaining functional correctness. The work is technically sound with a well-designed methodology, including candidate generation, correctness filtering, energy measurement with CodeCarbon, and reranking. The experimental setup is carefully controlled, and the statistical analysis is appropriate. However, the approach is incremental, serving as a post-processing reranking rather than fundamentally changing code generation. The paper is well-written, clearly organized, and the methodology is easy to follow. The significance is limited by the modest energy savings (1.86% vs best-time baseline), evaluation on a single hardware platform and language, and a small benchmark of 10 simple tasks. The originality lies in the combination of LLM code generation with energy-guided reranking, though the individual components are not novel. Reproducibility is strong, with detailed documentation and a promise to release code/data. Ethics and limitations are adequately discussed, and related work is comprehensively covered. Major concerns include limited scope, modest improvements, incremental nature, scale dependency, and the validity of energy measurements. Minor issues include basic benchmark tasks, lack of comparison with other techniques, and limited analysis of energy efficiency. Overall, the work addresses an important problem and provides a reasonable proof-of-concept, but the contributions are incremental and the evaluation is limited in scope. The practical impact and broader applicability remain unclear."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission258/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775582472,
    "mdate": 1760632211646,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "lrN2qkUlWS",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "decision": {
        "value": "Accept"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! Congratualations on the acceptance! Please see the reviews below for feedback."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission258/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759948895424,
    "mdate": 1760632289994,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "TodVDF5jbF",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "title": {
        "value": "This paper introduces energy-guided code generation, a method that reranks large language model (LLM)-generated code based on energy consumption measured with CodeCarbon, while ensuring correctness."
      },
      "summary": {
        "value": "The manuscript show that across a benchmark of algorithmic and data-processing tasks, their approach reduces average energy consumption by 44.7% compared to the Top-1 baseline, and by 1.9% compared to the fastest implementations, without runtime penalties. The work is positioned as the first to explicitly embed energy-awareness into the act of code generation.\n\nThis paper addresses a timely and important problem and provides reproducible evidence of substantial energy savings. However, limitations in scope, measurement fidelity, and robustness should be addressed before claiming broad generality."
      },
      "strengths_and_weaknesses": {
        "value": "Strength\nThe paper addresses an under-explored area — making LLM-based program generation energy-aware at the moment of creation. The pipeline is well described (Figure 1, p.3), including candidate generation, correctness filtering, CodeCarbon-based energy measurement, and reranking. Statistically significant improvements are demonstrated across 10 diverse benchmark tasks (sorting, numeric computation, graph traversal, I/O).\n\nWeakness\n\nOnly Python code was tested, with NumPy and standard library. It remains unclear how the approach scales to other languages or more complex frameworks.\n\nBenchmarks are limited to 10 relatively small algorithmic/data-processing tasks; more diverse real-world workloads (e.g., deep learning pipelines, large-scale ETL, or distributed systems) would strengthen claims of generalizability.\n\nCodeCarbon provides model-based estimates, not direct hardware-level measurements. The paper acknowledges this, but does not validate results against ground-truth hardware counters. This raises questions about measurement fidelity, particularly for small runtime differences.\n\nReranking requires executing multiple candidate programs per task. While feasible for small benchmarks, the overhead in real-world large-scale systems (e.g., thousands of lines of code or large databases of candidates) is not assessed.\n\nLow figure quality and old references."
      },
      "quality": {
        "value": 2
      },
      "clarity": {
        "value": 3
      },
      "significance": {
        "value": 2
      },
      "originality": {
        "value": 2
      },
      "questions": {
        "value": "1. Validate CodeCarbon measurements against hardware-based counters for at least a subset of tasks.\n\n2. Expand benchmarks to include larger, more realistic workloads and multiple programming languages (at least more than 1).\n\n3. Analyze computational cost of reranking itself (energy and runtime overhead of measuring multiple candidates).\n\n4. Explore robustness under noisy conditions (e.g., background processes, variable hardware loads).\n\n5. Provide uncertainty estimates (confidence intervals) for reported percentage savings, not only p-values.\n\n6. Clarify the novelty by contrasting more directly with related work on compiler-level optimizations and prior attempts at green software design.\n\n7. Consider integrating scale-aware or adaptive reranking strategies since optimal candidates shift with input size."
      },
      "limitations": {
        "value": "Yes"
      },
      "overall": {
        "value": 4
      },
      "confidence": {
        "value": 4
      },
      "ethical_concerns": {
        "value": "No issue"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission258/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759429352519,
    "mdate": 1760632212396,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_FfpB"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission258/Reviewer_FfpB"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "BxscqmB9Rs",
    "forum": "BxscqmB9Rs",
    "content": {
      "title": {
        "value": "Green by Design: Energy-Guided Reranking of LLM-Generated Programs"
      },
      "authors": {
        "value": [
          "Yi Xia",
          "José M. Aragón-Jurado",
          "Ruck Thawonmas"
        ]
      },
      "authorids": {
        "value": [
          "~Yi_Xia4",
          "josemiguel.aragon@uca.es",
          "~Ruck_Thawonmas1"
        ]
      },
      "keywords": {
        "value": [
          "Green Software",
          "Energy-Efficient Code Generation",
          "Sustainable Computing"
        ]
      },
      "TLDR": {
        "value": "We show that large language models can generate multiple correct code implementations and, by reranking them using measured energy consumption, select versions that significantly reduce software's carbon footprint."
      },
      "abstract": {
        "value": "The carbon footprint of computing is increasingly shaped by software, yet existing programming tools and large language models (LLMs) remain largely energy-blind. We propose energy-guided code generation, a method that reranks LLM-generated programs based on direct energy measurements using CodeCarbon while ensuring functional correctness. Evaluating a benchmark of algorithmic and data-processing tasks, we show that energy-guided selection yields statistically significant energy reductions. It reduces consumption by an average of 44.69% compared to unguided Top-1 candidates and by an additional 1.86% compared to the fastest (Best-Time) implementations, all without runtime penalties or loss of accuracy. These results provide the first conclusive evidence that LLMs produce diverse implementations with substantial variation in energy use, and that energy-aware reranking can consistently surface verifiably greener solutions. By embedding energy as a first-class optimization signal in the act of code generation, this work establishes a foundation for green-by-design software generation systems, where sustainability is not an afterthought but a default property of programming tools."
      },
      "pdf": {
        "value": "/pdf/e7544708fd6a00e5fb201d30f3ea905442f4facf.pdf"
      },
      "venue": {
        "value": "Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference"
      },
      "_bibtex": {
        "value": "@inproceedings{\nxia2025green,\ntitle={Green by Design: Energy-Guided Reranking of {LLM}-Generated Programs},\nauthor={Yi Xia and Jos{\\'e} M. Arag{\\'o}n-Jurado and Ruck Thawonmas},\nbooktitle={Open Conference of AI Agents for Science 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=BxscqmB9Rs}\n}"
      },
      "supplementary_material": {
        "value": "/attachment/61d114104df189c2cedf930558c4abaefeba3475.zip"
      },
      "paperhash": {
        "value": "xia|green_by_design_energyguided_reranking_of_llmgenerated_programs"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/Submission258/-/Revision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757997873723,
    "pdate": 1759960943504,
    "odate": 1758112145415,
    "mdate": 1760749483792,
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission258/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "8sltladLDY",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper proposes energy-guided reranking of LLM-generated programs, generating multiple candidate implementations with Code Llama, enforcing correctness via tests, measuring process-level energy via CodeCarbon, and selecting the lowest-energy correct candidate. On a benchmark of 10 tasks, the method reports substantial energy savings versus Top-1 candidates (average 44.69%) and a modest average advantage versus the fastest (Best-Time) implementation (1.86%) with negligible runtime penalty. The pipeline and experimental setup are clearly illustrated, and the artifact link is provided.\n\nStrengths include the importance and timeliness of the problem, a conceptually sound approach, reasonable experimental protocol, and statistical testing. However, there are significant concerns: the validity of energy measurement (relying solely on CodeCarbon's model-based estimates on a single Apple M2 Ultra system without hardware calibration), lack of control for system effects (especially for I/O tasks), correctness only enforced on small inputs, incomplete operational details (number of candidates, decoding hyperparameters, seeds), and potentially overstated claims given the limitations. Clarity is generally high, but some specifics are missing and there is a minor inconsistency in the task count. The paper addresses an important gap and is original in applying energy as a reranking criterion, but should relate more directly to established autotuning and measurement-based optimization literature. Reproducibility is supported by the artifact, but key details and ablations are missing. The discussion of societal impacts is balanced, but limitations should be discussed more candidly. Citations are adequate but could be improved by including relevant autotuning literature.\n\nActionable suggestions include validating energy measurement with hardware calibration and cross-platform replication, strengthening experimental control (especially for I/O tasks and correctness at scale), reporting missing details and ablations, broadening the scope of evaluation, and tempering claims. Overall, the paper is timely and well-written with a promising idea, but the strength of the conclusions is undermined by methodological limitations and incomplete reporting. With suggested revisions, it could become a strong contribution, but in its current form, it is a borderline reject."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission258/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775582081,
    "mdate": 1760632212104,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "7Gz99Yo5wA",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper introduces \"energy-guided code generation,\" a novel and timely method for producing more sustainable software using Large Language Models (LLMs). The core idea is to generate multiple candidate programs, filter them for correctness, and then rerank the valid candidates based on direct energy measurements to select the most energy-efficient one. Through a rigorous empirical evaluation on a benchmark of 10 diverse programming tasks, the authors demonstrate that this approach yields substantial energy savings (an average of 44.69%) compared to the default Top-1 LLM output. Furthermore, it achieves a modest but statistically significant additional energy reduction (1.86%) over the fastest correct implementation, with a negligible impact on runtime performance. The work provides the first conclusive evidence that LLMs generate code with significant energy diversity and that this diversity can be systematically exploited to create \"green-by-design\" software.\n\nThe submission is of exceptionally high quality and is technically sound. The methodology is logical, well-motivated, and straightforward to understand. The choice of Code Llama (70B) is appropriate, and the use of sampling to induce diversity is a standard technique applied effectively here. The experimental design is rigorous, with careful controls for confounding factors and a standard measurement protocol. The paper's central claims are strongly supported by the experimental results, with substantial and statistically significant energy savings shown using appropriate non-parametric tests. The authors are transparent about their methodology, particularly the use of CodeCarbon for energy estimation, and are upfront about the limitations of their work, which strengthens the paper's credibility.\n\nThe paper is exceptionally well-written, with a clear narrative and logical organization. The experimental setup is meticulously documented, leaving no ambiguity about how the study was conducted. The significance of this work is profound, addressing a clear and important gap in the literature. The impact is high, offering an immediately practical solution and challenging long-held heuristics in performance optimization. The work is highly original, being the first to propose and systematically evaluate the use of direct energy measurement as the primary signal for reranking LLM-generated source code, and it innovatively connects generative AI and green software engineering.\n\nThe authors have made an exemplary effort to ensure reproducibility, providing detailed descriptions and an anonymized repository with all necessary materials. They also provide a thoughtful and responsible discussion of the broader implications of their work, identifying both positive societal benefits and potential negative consequences.\n\nConstructive feedback includes: (1) validating the energy proxy with hardware-based measurements, (2) discussing the computational/energy overhead of the reranking process, and (3) providing a qualitative analysis of why certain code candidates are more efficient.\n\nIn conclusion, this is a seminal paper that is technically sound, highly original, and addresses a problem of significant and growing importance. It is exceptionally well-executed and presented, making it a perfect fit for the Agents4Science conference and representing the pioneering work the venue aims to attract."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 6
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 6
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission258/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775582261,
    "mdate": 1760632211752,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "5B2WWnyArH",
    "forum": "BxscqmB9Rs",
    "replyto": "BxscqmB9Rs",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Energy measurement precision on Apple Silicon: CodeCarbon’s model-based estimates and 0.1s sampling are practical for relative ranking but may have limited precision. Given an energy CV ≈10.75% (page 6), the small mean gain vs Best-Time (1.86%) warrants per-task confidence intervals and clearer unit-of-analysis disclosure for the Wilcoxon tests.\n- Single-thread enforcement for NumPy on macOS: The environment variables listed (OPENBLAS_NUM_THREADS, MKL_NUM_THREADS, OMP_NUM_THREADS; Table 1) may not control threading if NumPy is linked against Accelerate/vecLib. Consider documenting the BLAS backend and, if Accelerate is used, setting VECLIB_MAXIMUM_THREADS to ensure fairness.\n- Correctness validation only on small inputs: While practical, it does not fully guarantee correctness at the large scales used for energy measurements. Adding spot checks at larger scales or randomized property tests would strengthen the ‘ensuring functional correctness’ claim.\n- I/O caching and warm/cold runs: For I/O-bound tasks, absence of explicit cache control may bias energy/time measurements. Documenting cache-handling (e.g., clearing caches, using unique temp files, or reporting both cold and warm runs) would improve rigor.\n- Statistical reporting detail: Specify the unit of analysis (e.g., per task-scale pair) and sample sizes used in Wilcoxon tests; report effect sizes or confidence intervals per task to contextualize the modest mean gains vs Best-Time.\n- Baseline definitions clarity: Clarify the Top-1 baseline precisely (e.g., first valid under a specific decoding configuration) and confirm that Best-Time is selected using the same repeated-run median procedure as energy, to ensure comparability.\n- Hardware generalizability: Results are from a single Apple Silicon machine; calling out potential differences on x86/Linux and GPUs and adding a brief sensitivity analysis in supplemental material would increase external validity."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776769353,
    "mdate": 1760640225021,
    "signatures": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission258/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]