[
  {
    "id": "z6VXV0hCtq",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "decision": {
        "value": "Reject"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! We regret to inform you that your submission has not been accepted. Please see the reviews below for more information."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission179/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759948925526,
    "mdate": 1760632281664,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "yLAQozG9uZ",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Formal inconsistency: initialization claims duplicates increase starting scores, but s0_i(f) = 1 contradicts that (Section 3.2 vs. Belief updating).\n- Statistical inference likely optimistic: bootstrap and permutation tests appear to treat agents as iid despite network dependence; permutation test details (null, permutation scheme) are not specified.\n- Confounding by bandwidth: centrality–performance correlations are pooled by regime without conditioning on B, even though B strongly affects outcomes and is unevenly sampled across regimes (Table 1, page 5).\n- Unclear effect size reporting: Cohen’s d > 2 is stated without defining grouping (e.g., which centrality quantiles), preventing reproduction.\n- Centrality definitions under-specified: handling of closeness/eigenvector in potentially disconnected graphs is not described, affecting reproducibility.\n- Potential bias from early stopping: correlations and accuracies are evaluated at termination (first-proposer rule), which may advantage central nodes; no fixed-time robustness checks for the correlation analysis are reported.\n- Limited seeds (n=3 per condition) and single-network scope reduce statistical robustness of threshold and correlation claims."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776763387,
    "mdate": 1760639953077,
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "xYUNkQ4vKK",
    "forum": "xYUNkQ4vKK",
    "content": {
      "title": {
        "value": "Phase Transitions and Hub Vulnerability in Networked Truth Recovery under Misinformation"
      },
      "keywords": {
        "value": [
          "network science",
          "social simulations",
          "LLMs",
          "centrality",
          "hubs"
        ]
      },
      "TLDR": {
        "value": "LLM-based simulations of agents on networks"
      },
      "abstract": {
        "value": "This paper examines how networked agents recover ground truth when initial knowledge is incomplete and contaminated by misinformation. We ask: (1) under what conditions can networks reconstruct the correct knowledge base, (2) how does centrality affect recovery across informational environments, and (3) what structural vulnerabilities emerge when misinformation dominates? We develop a multi-agent simulation where agents begin with a mix of true and false facts, exchange information with neighbors, and update beliefs using a redundancy-based scoring rule with contradiction resolution. The system aims to reconstruct the full ground-truth knowledge base. Experiments on the ca-GrQc collaboration network reveal abrupt bandwidth thresholds: below a critical share budget (the maximum number of facts an agent can transmit per round), convergence never occurs; above it, recovery typically completes within 1--3 rounds and yields complete accuracy across agents that converge. Information quality defines three regimes. In clean environments (truth $\\geq 70\\%$), centrality strongly predicts success. At a boundary near 50\\% truth, centrality effects collapse ($\\rho \\approx 0.2$ or less). In polluted environments (truth $\\leq 40\\%$), central nodes amplify errors, producing a \\emph{hub vulnerability paradox}. These findings identify structural weaknesses in information systems and show that resilience depends jointly on communication capacity, network topology, and information quality."
      },
      "pdf": {
        "value": "/pdf/29da4f51d2f1be9559f41234da067a6e6c4d82b9.pdf"
      },
      "venue": {
        "value": "Submitted to Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference/Rejected_Submission"
      },
      "_bibtex": {
        "value": "@misc{\nanonymous2025phase,\ntitle={Phase Transitions and Hub Vulnerability in Networked Truth Recovery under Misinformation},\nauthor={Anonymous},\nyear={2025},\nurl={https://openreview.net/forum?id=xYUNkQ4vKK}\n}"
      },
      "supplementary_material": {
        "value": "/attachment/3bda00cd908a4b329255cebfd86b0e51f33e30ef.zip"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/Submission179/-/Revision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757903575186,
    "odate": 1758112145415,
    "mdate": 1759960939767,
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission179/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "rUzVOlZ5kd",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper presents a clear and minimal model for collective truth recovery on a large empirical network, revealing compelling phenomena such as sharp bandwidth thresholds and the 'hub vulnerability paradox.' The work is well written, transparent, and demonstrates practical relevance for social systems and multi-agent LLM design. However, the study is limited by its reliance on a single network, lack of theoretical analysis for the observed phase transitions, potential confounds in evaluation timing, and insufficient ablations and external validation. The statistical analysis could be strengthened, and the novelty should be better situated within existing literature. While the findings are promising and the paper is well-executed as a baseline, it currently falls short of the rigor and breadth required for strong acceptance. With the recommended expansions and deeper analysis, it could become a solid contribution. In its present form, a borderline reject is recommended."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission179/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775565729,
    "mdate": 1760632188412,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "YX97U4fVWE",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper examines networked truth recovery under misinformation through multi-agent simulation, studying how communication bandwidth, information quality, and network topology affect collective belief formation. I'll evaluate this systematically across key dimensions.\n\nQuality:\nThe paper is technically sound with a well-designed simulation framework. The methodology is clearly specified - agents start with mixed true/false facts, exchange information with neighbors, and update beliefs using redundancy-based scoring with contradiction resolution. The experimental design systematically varies information quality (5 regimes from 87.5% to 37.5% truth) and communication bandwidth (12 values from B=1 to B=20) across 93 runs with over 150,000 agent records. The statistical analysis includes appropriate measures (Spearman correlations, bootstrap CIs, permutation tests). The three main findings are well-supported: phase transitions in recovery, centrality effects that reverse with information quality, and rapid convergence timing.\n\nClarity:\nThe paper is well-organized and clearly written. The abstract effectively summarizes the key contributions. The methodology section provides sufficient detail for understanding the simulation mechanics. Figures are informative, particularly Figure 2 showing convergence outcomes and Figure 3 illustrating the hub vulnerability paradox. The mathematical notation is appropriate and equations are clearly presented. Some minor verbosity could be reduced, but overall the presentation is clear.\n\nSignificance:\nThe findings have important implications for understanding information dynamics in social networks and emerging AI systems. The \"hub vulnerability paradox\" - where central nodes amplify misinformation in polluted environments rather than facilitating truth recovery - is a valuable contribution that challenges conventional wisdom about network diffusion. The identification of sharp bandwidth thresholds and three distinct informational regimes (clean, boundary, polluted) provides actionable insights for system design. The connection to LLM multi-agent systems adds contemporary relevance.\n\nOriginality:\nThe work provides novel insights by systematically studying the interplay between network structure, information quality, and communication constraints. The hub vulnerability paradox appears to be a new finding that reverses classical expectations about centrality benefits. The identification of sharp phase transitions in truth recovery (rather than gradual improvement) is also novel. The framework connecting network science, social learning, and emerging AI systems represents an innovative approach.\n\nReproducibility:\nThe paper provides excellent reproducibility details. The ca-GrQc network is publicly available, all experimental parameters are specified, and the simulation algorithms are mathematically described. The use of fixed random seeds (42, 43, 44) and detailed statistical methodology enables replication. The authors commit to releasing code upon acceptance. The LLM demonstrations are described sufficiently for replication, though they serve only as illustrative examples.\n\nEthics and Limitations:\nThe authors are refreshingly honest about limitations, noting that agents use only redundancy-based updating without credibility assessment, making results a \"conservative lower bound.\" They acknowledge assumptions about independent facts, static networks, and uniform communication protocols. The broader impacts section appropriately discusses both positive applications (robust system design) and potential risks (understanding vulnerabilities). The research uses only publicly available data and synthetic simulations, avoiding ethical concerns.\n\nCitations and Related Work:\nThe related work section adequately situates the research within the broader context of LLM-based social simulation, though it could benefit from stronger connections to classical social learning and network diffusion literature. The distinction between individual, scenario, and society-level simulation provides useful framing. Citations appear comprehensive and appropriate.\n\nStrengths:\n- Rigorous experimental design with systematic parameter variation\n- Novel and counterintuitive findings (hub vulnerability paradox)\n- Strong statistical methodology with appropriate confidence intervals\n- Clear practical implications for system design\n- Excellent reproducibility documentation\n- Transparent about AI involvement and limitations\n\nWeaknesses:\n- Limited to one network topology (ca-GrQc)\n- Simple redundancy-based updating rule may not reflect real cognitive processes\n- LLM demonstrations are illustrative only, not systematic\n- Could benefit from theoretical analysis of the phase transitions\n- Some verbosity in presentation\n\nMinor Issues:\n- Some figures could be larger for better readability\n- The connection between symbolic and LLM results could be strengthened\n- Future work section could be more specific about next steps\n\nThis is a well-executed study that makes meaningful contributions to understanding information dynamics in networks. The hub vulnerability paradox is particularly valuable, and the systematic experimental approach provides robust evidence for the claims. While there are limitations, the authors are transparent about them and the findings advance our understanding of collective truth recovery under misinformation."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 5
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 5
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission179/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775566337,
    "mdate": 1760632188128,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "78WGHvluy4",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents a multi-agent simulation to study how networked agents collectively recover a ground-truth knowledge base from partial and noisy initial information. Using a simple redundancy-based belief updating heuristic on a large, real-world collaboration network, the authors uncover three key findings: (1) truth recovery exhibits phase transition behavior, succeeding reliably only above a critical communication bandwidth; (2) the role of network hubs is conditional on information quality, leading to a \"hub vulnerability paradox\" where central nodes that accelerate truth in clean environments amplify falsehood in polluted ones; and (3) when recovery occurs, it is extremely rapid, happening within a few rounds. The authors frame these symbolic simulations as a baseline for understanding potential vulnerabilities in emerging multi-agent LLM systems, supported by small-scale illustrative demonstrations using LLaMA 3.\n\nThe paper is of exceptional technical quality. The methodology is clear, well-justified, and appropriate for the research questions. The choice to use a minimal agent model (\"deliberately simple\") is a significant strength, as it allows the authors to isolate the effects of network structure, information quality, and bandwidth, establishing a conservative lower bound on performance. The experimental design is rigorous, systematically exploring a well-chosen parameter space across different information regimes and communication bandwidths. The use of a real-world network (ca-GrQc) adds to the realism and relevance of the findings.\n\nThe claims are strongly supported by the experimental results. The phase transitions are clearly visible in Figure 2, and the \"hub vulnerability paradox\" is compellingly demonstrated in Figure 3 through robust statistical analysis (Spearman correlations with bootstrap confidence intervals). The work is a complete and polished piece of research.\n\nThe paper is a model of clarity. It is exceptionally well-written, with a logical flow from motivation to conclusion. The abstract and introduction perfectly frame the problem and summarize the contributions. The methodology section provides all necessary details for an expert to understand and replicate the simulation. The figures are clean, informative, and effectively communicate the main results. The prose is concise and precise, which is particularly impressive given the authors' transparent statement about the substantial use of AI in drafting the manuscript—it demonstrates a high level of human oversight and editing.\n\nThe significance of this work is very high. The \"hub vulnerability paradox\" is a powerful and memorable concept that has profound implications for our understanding of information ecosystems, from social media to scientific collaboration and organizational knowledge sharing. It elegantly shows that structural properties like centrality are not universally beneficial; their value is contingent on the quality of the information environment. The discovery of sharp, phase-transition-like behavior in truth recovery is also a major contribution, highlighting the potential for abrupt systemic failure in information networks.\n\nThe paper's connection to multi-agent LLM systems is timely and important. As these systems become more prevalent, understanding their potential emergent failure modes is critical. This work provides a foundational, principled framework for studying these dynamics, moving beyond anecdotal observations to systematic simulation. The findings will likely be influential and widely cited, inspiring future work in network science, computational social science, and AI safety.\n\nThe paper demonstrates a high degree of originality. While the components (agent-based modeling, network analysis, misinformation studies) are not new in isolation, their synthesis is novel and powerful. The formalization and empirical demonstration of the \"hub vulnerability paradox\" is a core original contribution. Similarly, framing collective truth recovery as a process with distinct phase transitions dependent on communication bandwidth is a novel insight that advances the field beyond simpler models of information diffusion. The work successfully carves out a unique and valuable niche at the intersection of several fields.\n\nThe authors have provided an excellent blueprint for reproducibility. The dataset is public, and all parameters, agent rules, and experimental settings are described in sufficient detail in the Methodology and Experimental Setup sections. While the code is not provided with the submission, the authors promise to release it upon acceptance, which is standard and acceptable practice. The clarity of the description instills high confidence that the results are reproducible.\n\nThe authors are commendably transparent about the limitations of their study, dedicating a section to discussing the simplifying assumptions (e.g., redundancy-based updates, static network) and outlining clear directions for future work. This honesty strengthens the paper significantly. There are no ethical concerns with the methodology.\n\nFurthermore, the authors' transparency regarding the use of AI in the research process is exemplary and perfectly aligns with the ethos of the Agents4Science conference. The \"Observed AI Limitations\" section is a fantastic and insightful addition, providing a candid account of the challenges and the necessity of human oversight in AI-assisted science. This level of reflection should be encouraged and sets a high standard for future submissions.\n\nThis is a groundbreaking paper that is technically flawless, highly original, and of significant impact. It tackles a fundamental problem with a rigorous and elegant approach, yielding clear and important insights. The \"hub vulnerability paradox\" is a major conceptual contribution that will shape future discourse on the resilience of information networks, both human and artificial. The paper is exceptionally well-written and presented. It represents the very best of what agent-based modeling can achieve and is a perfect fit for the Agents4Science conference. I recommend it for acceptance without any reservations and expect it to be one of the standout papers of the conference."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 6
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 6
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission179/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775566055,
    "mdate": 1760632188264,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "5ulHhJTSvS",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "title": {
        "value": "This is a poorly written paper, though exploring interesting problems"
      },
      "summary": {
        "value": "I am not an expert in social science, here are my feedbacks\n\n1. the authors(agents) use a social network system of simulator agents to understand how multi-party group work together to discovery ground truth/knowledge \n\n2. They conducted experiments using LLama to simulate the process \n\n3. from the LLama agent behavior they identified phase transitions and a hub vulnerability paradox"
      },
      "strengths_and_weaknesses": {
        "value": "The usage of LLM agents to explore social science problem of truth discovery is novel \n\nHowever, the paper is poorly organized for the following reasons\n\n1 Not enough background given in the writting for researchers from general science/AI background \n\n2. experiments are not enough , only on LLama agents. More LLMs , and more configuration are needed \n\n3. In results in figure 3, no error bar/p=values are given."
      },
      "quality": {
        "value": 1
      },
      "clarity": {
        "value": 2
      },
      "significance": {
        "value": 3
      },
      "originality": {
        "value": 2
      },
      "questions": {
        "value": "1. the bandwidth and other setting can be varied more to understand model performance \n\n2. multiple language should be evaluated \n\n3.it is about communication, maybe both collborative and competitive setting should be checked?\n\n4. How about the COT affect the communication and truth discovery (eg. use GPT-5/Claude)"
      },
      "limitations": {
        "value": "Though the study investigated an interesting question . the study design and experiment excecuted do not give solid answers"
      },
      "overall": {
        "value": 2
      },
      "confidence": {
        "value": 5
      },
      "ai_review_score": {
        "value": 0
      },
      "ethical_concerns": {
        "value": "NA"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission179/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759832196362,
    "mdate": 1760632188004,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_s8XL"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission179/Reviewer_s8XL"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "4UvupuKDno",
    "forum": "xYUNkQ4vKK",
    "replyto": "xYUNkQ4vKK",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nPlease look at your references to confirm they are good.\n\n**Examples of references that could not be verified (they might exist but the automated verification failed):**\n\n- Society simulation for testing social science theories by Chuang et al.\n- Algorithmic fidelity in llm agents by V. Chaudhary and A. Chaudhary\n- Towards autonomous agents with llms: A survey of single-agent and multi-agent systems by Jiaxin Xu et al."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777909178,
    "mdate": 1760639952393,
    "signatures": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission179/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]