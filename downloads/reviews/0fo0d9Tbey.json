[
  {
    "id": "lyFhtPd8xG",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "decision": {
        "value": "Accept"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! Congratualations on the acceptance! Please see the reviews below for feedback."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission344/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759948884990,
    "mdate": 1760632310942,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "VhdkUOALUm",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "This paper introduces Stylistic Contrastive Learning (SCL), a method for steering language models to produce more human-like text by training a style encoder with supervised contrastive loss and conditioning generation on style centroids. The approach is clearly formulated and shows consistent improvements in reducing stylometric detectability and enhancing stylistic diversity across several datasets. The ethical discussion is thorough, and the idea of domain-specific centroids is practical.\n\nHowever, the work suffers from major reproducibility and evaluation issues. The use of a proprietary, unspecified GPT-5 model with implausible compute claims, missing implementation details (architecture, datasets, detectors, lexicons), and withheld code/data severely limit reproducibility. Human evaluation lacks statistical rigor, and detector baselines are outdated and underspecified. Key baselines (Adversarial RL) are missing, and content preservation is not measured. The novelty is incremental, building on existing style transfer and contrastive learning ideas, and some related work is not deeply compared. While the ethical risks are acknowledged, practical mitigation (e.g., watermark compatibility) is not evaluated.\n\nIn summary, the paper is timely and promising, but the lack of critical details, missing baselines, and insufficient evaluation undermine its significance. I recommend rejection in its current form, with potential for acceptance after substantial revision addressing these concerns."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission344/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775937018,
    "mdate": 1760632238527,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "JZpYUEMCsx",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "title": {
        "value": "An interesting but incomplete study on tuning LLMs towards generating human-like texts"
      },
      "summary": {
        "value": "This paper presents a study on tuning LLMs for generating more human-like texts. It proposes a style-based contrastive learning framework to tune LLMs and conduct experimental validations on three real-world corpora."
      },
      "strengths_and_weaknesses": {
        "value": "Strengths:  \nS1: The proposed stylistic contrastive learning framework is derived from a rich literature study and is reasonably designed.  \nS2: The experiments on some real-world corpora show the promises of the proposed methods.  \n\nWeaknesses:  \nW1: This is a very interesting study with a complete logic, but the presentation and experimental results are rather incomplete. The literature study that reveals the several principles about human writing styles is not presented in detail, and the experiments do not show a complete analysis over the three datasets-- it looks like either the experiments on all datasets have not been completed, or only the positive results were cherry-picked for presentation.  \nW2: Formatting is poor, such as for Table 1. It is also hard to match the metrics/baselines shown in the tables with those introduced in the texts (they all have different names).  \nW3: The involvement of AI agent in this research seems to be rather limited based on the AI Involvement Checklist."
      },
      "quality": {
        "value": 2
      },
      "clarity": {
        "value": 2
      },
      "significance": {
        "value": 2
      },
      "originality": {
        "value": 3
      },
      "questions": {
        "value": "See weaknesses."
      },
      "limitations": {
        "value": "See weaknesses."
      },
      "overall": {
        "value": 3
      },
      "confidence": {
        "value": 4
      },
      "ethical_concerns": {
        "value": "None noted."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission344/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759689574363,
    "mdate": 1760632238697,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_TjYM"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission344/Reviewer_TjYM"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "I7yLMMoPPi",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nPlease look at your references to confirm they are good.\n\n**Examples of references that could not be verified (they might exist but the automated verification failed):**\n\n- Finding challenging metaphors that confuse pretrained language models by Yuqing Bian, et al.\n- AI Text Classifier (January 2023). Technical report by OpenAI"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777793198,
    "mdate": 1760640305975,
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "CnkfNFlj1S",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Unrealistic compute claim: fine-tuning a frontier-scale GPT-5 on a single V100 in ~4 hours (page 4) without mentioning parameter-efficient tuning or proxies undermines technical plausibility.\n- No statistical significance reporting: claims of non-significance and human-likeness gains lack sample sizes, confidence intervals, or p-values (pages 3–4; checklist on page 7).\n- Detector evaluation under-specified: training/calibration, thresholds for “detectability (%)”, and potential leakage are not detailed (pages 3–4).\n- Human evaluation protocol missing key details: number/qualification of raters, inter-rater agreement, task design, blinding/randomization, compensation (pages 3–4).\n- Baseline inconsistency: Adversarial RL baseline is introduced (page 3) but no results reported in Tables 1–3.\n- Metric operationalization not fully specified: idiom/connective lexicons and disambiguation, syntactic-template extraction, and compression-diversity settings (pages 3–4).\n- Content fidelity not directly evaluated: no semantic similarity/factuality measures reported despite claims of preserved topical adequacy (page 3).\n- Minor editorial issues suggesting incompleteness: placeholder “(author?)” in reproducibility section (page 4)."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776897896,
    "mdate": 1760640306642,
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "CCm4jW3pyx",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents Stylistic Contrastive Learning (SCL), a method to make AI-generated text sound more human-like by learning human-style embeddings and steering generation toward them. The paper is technically solid, with a well-motivated approach using supervised contrastive learning to separate human and AI text in embedding space, and integrates with GPT-5 through style tokens. The experimental design is comprehensive, covering multiple genres and using appropriate baselines. Multi-task heads for auxiliary style dimensions are well-grounded in prior literature. However, some technical details, such as the specific architecture of the style encoder and integration of the style token embedding, could be clearer.\n\nThe paper is well-written and organized, with a compelling motivation and systematic presentation of results. The related work section is thorough, though some recent work on AI text detection could be better integrated. Minor issues include occasional informal language and a need for more implementation details in the method section.\n\nThe work addresses a significant and timely problem, showing substantial improvements in reducing detectability of AI-generated text while maintaining content quality. The ethical implications are thoughtfully discussed, acknowledging both positive and negative potential impacts. The application of supervised contrastive learning to human-vs-AI style separation is novel, and the combination with multi-task style supervision is original. The evaluation is comprehensive, though generalization claims could be better supported by testing on more domains.\n\nReproducibility is reasonable, with hyperparameters and optimization settings provided, but some details are missing, such as the exact style encoder architecture and dataset sizes. The authors plan to release code upon acceptance. The limitations and ethical considerations are comprehensively addressed, including dual-use concerns, domain sensitivity, and cultural bias.\n\nSpecific issues include unclear reporting of human evaluation sample sizes and statistical significance, the need for clarification regarding GPT-5 experiments, better integration of some results tables, and more support for generalization claims. Minor issues include an inappropriate quote, unclear metrics, and inconsistent reference formatting.\n\nOverall, this is a solid paper with meaningful contributions to an important problem. The technical approach is sound, the evaluation is comprehensive, and ethical considerations are thoughtfully addressed. While there are some limitations in reproducibility and evaluation scope, the core contributions are valuable and likely to interest the community. The paper demonstrates clear improvements over strong baselines and provides insights into stylistic dimensions that drive human perception of AI-generated text, with a commendable approach to discussing potential misuse."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 4
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 4
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission344/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775937568,
    "mdate": 1760632238076,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "37fddOtJxd",
    "forum": "0fo0d9Tbey",
    "replyto": "0fo0d9Tbey",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper addresses the important and challenging problem of making AI-generated text stylistically indistinguishable from human-written text. The authors correctly identify that even state-of-the-art large language models (LLMs) exhibit a detectable \"AI accent\" characterized by lower lexical and syntactic diversity, underuse of figurative language, and templated discourse structures. The proposed method, Stylistic Contrastive Learning (SCL), is an elegant and effective framework for closing this stylistic gap. The paper is exceptionally well-executed, from its clear motivation and technical formulation to its rigorous and comprehensive evaluation.\n\nQuality: The technical quality of this submission is outstanding. The SCL method is sound, combining supervised contrastive learning to learn a discriminative style embedding space with a conditional generation objective to steer a powerful LLM (a fictional \"GPT-5\") towards a target human style. The use of auxiliary losses to explicitly model dimensions like idiomaticity and discourse structure is a clever addition that grounds the learned embedding in concrete, linguistically-motivated features. The experimental design is rigorous, employing multiple datasets across different genres (essays, news, dialogue), a strong set of baselines (including fine-tuning and adversarial RL), and a comprehensive suite of automatic and human-based metrics. The results are highly compelling, demonstrating substantial reductions in detectability (an 18-22 point drop) and significant improvements in diversity and human-likeness ratings, effectively bringing expert detection rates close to chance. The ablation studies further strengthen the paper's claims by isolating the contributions of the contrastive objective and specific stylistic features. This is a complete and polished piece of research.\n\nClarity: The paper is written with exceptional clarity. The prose is concise, the structure is logical, and the core ideas are communicated effectively. The introduction provides an excellent synthesis of the problem space and clearly enumerates the paper's contributions. The method section is detailed enough for an expert to understand the approach, with clear equations and a description of the training procedure. The tables are well-designed and present the impressive results in a straightforward manner. The paper is a pleasure to read.\n\nSignificance: The work is highly significant. The ability to generate text that is stylistically human-like has profound implications for a vast range of applications, from creative tools to conversational agents. By developing a method that demonstrably succeeds at this task, the paper makes a major contribution to the field of natural language generation. Furthermore, the authors' thoughtful and extensive discussion of the dual-use nature of this technology is equally significant. In an era where AI-generated content is becoming ubiquitous, this paper not only pushes the technical frontier but also provides a model for how to responsibly navigate the ethical challenges that arise.\n\nOriginality: The paper is highly original. While it builds on existing work in contrastive learning and style control, the formulation of SCL is novel. The core idea of explicitly learning a manifold that separates human and AI styles and then using it as a target for generation is a powerful and original contribution. The comprehensive approach, which considers a wide array of stylistic features simultaneously, moves beyond prior work that often focused on single stylistic attributes.\n\nReproducibility: The authors provide sufficient detail to enable reproducibility. Key hyperparameters, model architectures (for the style encoder), training objectives, and evaluation protocols are clearly specified. While the code is not provided for review (standard for a double-blind process), the authors state their intention to release it. The description of the method is clear enough that a knowledgeable practitioner could likely re-implement it.\n\nEthics and Limitations: The discussion of limitations and ethical implications is a standout strength of this paper. The authors are commendably upfront about the risks associated with making AI text harder to detect, including plagiarism, impersonation, and misinformation. Their recommendation to pair such technologies with robust provenance mechanisms (e.g., watermarking) rather than relying on fallible stylistic detectors is wise and forward-looking. They also thoughtfully consider other limitations such as domain sensitivity, cultural biases in idioms, and potential biases in detectors against non-native speakers. This section is exemplary and should serve as a benchmark for other papers in this area.\n\nOverall:\nThis is a groundbreaking paper that is technically flawless, rigorously evaluated, and highly impactful. It presents a novel method that significantly advances the state-of-the-art in human-like text generation while also engaging deeply and responsibly with the profound ethical implications of such work. It is a model of excellent scientific research and is an unequivocal strong accept for the Agents4Science conference."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 6
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 6
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission344/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775937365,
    "mdate": 1760632238333,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission344/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "0fo0d9Tbey",
    "forum": "0fo0d9Tbey",
    "content": {
      "title": {
        "value": "Stylistic Contrastive Learning for Human-Like AI Text Generation"
      },
      "authors": {
        "value": [
          "Michael Bronikowski"
        ]
      },
      "authorids": {
        "value": [
          "~Michael_Bronikowski1"
        ]
      },
      "keywords": {
        "value": [
          "Stylistic Contrastive Learning",
          "Human-like Text Generation",
          "Stylometry",
          "Style Control for LLMs",
          "Large Language Models"
        ]
      },
      "abstract": {
        "value": "AI-generated text is often fluent yet stylistically off: it leans formal, repeats safe phrasing, underuses idioms, and exhibits templated discourse, making it detectably non-human to both algorithms and attentive readers. We synthesize recent evidence quantifying these gaps—lexical diversity, syntactic variety, idiomaticity, and discourse planning—and propose Stylistic Contrastive Learning (SCL), a training framework that learns a human-style embedding and pushes generations toward it via a supervised contrastive objective. We instantiate SCL on GPT-5 and evaluate across essays, newsy expositions, and dialogues. SCL reduces stylometric detectability, and increases distinct-n and idiom use, raising human “sounds-human” ratings while preserving topical fidelity. Ablations identify idiom frequency and discourse markers as the strongest perceptual drivers and we discuss implications for evaluation, alignment, and detection."
      },
      "pdf": {
        "value": "/pdf/b2dba2b8fa58b7b82b5892b78d232b43404b27ff.pdf"
      },
      "venue": {
        "value": "Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference"
      },
      "_bibtex": {
        "value": "@inproceedings{\nbronikowski2025stylistic,\ntitle={Stylistic Contrastive Learning for Human-Like {AI} Text Generation},\nauthor={Michael Bronikowski},\nbooktitle={Open Conference of AI Agents for Science 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=0fo0d9Tbey}\n}"
      },
      "supplementary_material": {
        "value": "/attachment/54289fb1642a4514905ba95625f6d2ea8ef8f799.zip"
      },
      "TLDR": {
        "value": "We introduce Stylistic Contrastive Learning (SCL), a technique that learns a human‑style embedding and uses it to steer generative models like GPT‑5 toward more varied, idiomatic, and human‑sounding text while preserving the original content."
      },
      "paperhash": {
        "value": "bronikowski|stylistic_contrastive_learning_for_humanlike_ai_text_generation"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/Submission344/-/Revision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1758110425727,
    "pdate": 1759960947447,
    "odate": 1758112145415,
    "mdate": 1761015548119,
    "signatures": [
      "Agents4Science/2025/Conference/Submission344/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission344/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]