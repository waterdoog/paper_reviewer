[
  {
    "id": "pZujiKtNGI",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper investigates the performance of several well-known algorithms for imperfect information games in No-Limit Hold'em poker, aiming to evaluate their convergence to Game-Theory Optimal (GTO) strategies and extensibility to multi-player scenarios. While the paper is well-written and addresses an important topic, it suffers from a fundamental methodological flaw: the \"GTO-proxy\" used as ground truth is a simple, hand-crafted heuristic based on hand equity, not a true or even reasonable approximation of a GTO strategy. This misunderstanding invalidates the main claims and conclusions, as the evaluation measures how well algorithms learn a simple function rather than converge to GTO. The problem is further abstracted by generating synthetic states with known equity, sidestepping the core challenge of imperfect information. Reported results are inconsistent and difficult to interpret, suggesting further issues with the experimental setup. While the paper is generally clear and well-contextualized, the misuse of the term \"GTO\" and lack of explanation for applying CFR-family algorithms to the synthetic state space hinder understanding and reproducibility. The significance of the research question is high, but the flawed methodology means the work makes no meaningful contribution. The novelty of the experimental framework is not positive due to its fundamental flaws. Reproducibility is limited by missing methodological details. The limitations section is transparent about some issues but omits the most critical flaw. In conclusion, the paper is not suitable for publication in its current form, and a strong rejection is recommended."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 1
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 1
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission163/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775983621,
    "mdate": 1760632183865,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "hKI5Ktu1ca",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper benchmarks poker agents combining a GTO-style baseline with adaptive exploitation, using CFR, MCCFR, DeepCFR, and NFSP on synthetic No-Limit Hold’em states. However, major methodological flaws undermine its claims: the 'GTO' target is a hand-crafted heuristic, not a true equilibrium; the action space is oversimplified to three actions, removing core NLHE complexity; there is ambiguity and circularity in the reference policy; reported metrics are inconsistent and sometimes implausible; and profit/adaptation are not measured. The paper is readable and cites key works, but lacks essential experimental details and credible evaluation. The study is incremental, with limited originality and significance due to its coarse abstraction and lack of empirical support for central claims. Reproducibility is poor due to missing details and questionable metrics. The limitations are acknowledged, and ethical concerns are low. Actionable suggestions include aligning claims with ground truth, measuring profit/adaptation, restoring NLHE essentials, fixing evaluation protocols, providing full implementation details, and calibrating the scope/title. Due to serious methodological inconsistencies, implausible metrics, and mismatch between claims and evidence, the paper is not ready for publication and requires substantial rework."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 2
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 2
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission163/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775982042,
    "mdate": 1760632184188,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "cuATggNcXu",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nNo hallucinated references detected."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777802594,
    "mdate": 1760640096831,
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "bl9gYcd4nY",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "decision": {
        "value": "Reject"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! We regret to inform you that your submission has not been accepted. Please see the reviews below for more information."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission163/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759950108235,
    "mdate": 1760632279367,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "ZqZFN9BrrA",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Use of KL(p||q) with a proxy q that assigns zero probability to some actions, without stated smoothing; reported finite KL values are mathematically unjustified.\n- Incompatible setup: CFR-family algorithms require an extensive-form game; training on independent synthetic states without a defined game tree, utilities, or information sets invalidates theoretical guarantees and raises applicability concerns.\n- Contradictory reference baselines: evaluation alternately cites a handcrafted GTO-proxy and a high-iteration MCCFR reference, with no clear alignment.\n- Multiway equity inconsistencies: Monte Carlo equity vs. heuristic e^(k−1) both claimed without reconciliation.\n- Implausible Top-1 accuracies: random baseline ≈0.600 in Table 2 and as low as 0.021 in Table 3 despite a three-action space; suggests serious evaluation or reporting errors.\n- Overstated claims: mentions of real-time exploitation and provable safety are not supported by experiments (no exploitability, no online opponent modeling results).\n- Missing experimental details: dataset sizes, exact CI computations, architectures/hyperparameters for DeepCFR/NFSP, convergence diagnostics.\n- No exploitability or NashConv metrics in two-player settings; no definition or results for the stated multiway NashConv.\n- GTO-proxy is overly simplistic (no stacks, pot sizes, positions, histories, or bet sizes), so matching it cannot substantiate proximity to GTO."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776911923,
    "mdate": 1760640097561,
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "Xh0s29VtbH",
    "forum": "Xh0s29VtbH",
    "content": {
      "title": {
        "value": "Beyond Game Theory Optimal: Profit-Maximizing Poker Agents for No-Limit Hold’em"
      },
      "keywords": {
        "value": [
          "Game theory",
          "GTO",
          "exploitative strategy",
          "counterfactual regret minimization (CFR)",
          "MCCFR",
          "Deep CFR",
          "NFSP",
          "multiway evaluation",
          "poker AI",
          "reinforcement learning",
          "self-play learning",
          "Nash equilibrium",
          "counterfactual regret",
          "regret minimization",
          "strategy convergence",
          "Monte Carlo sampling",
          "neural fictitious self-play",
          "poker simulation",
          "multi-agent systems"
        ]
      },
      "TLDR": {
        "value": "finding game theory optimal plays and exploiting oppenents in poker(no-limit hold'em)"
      },
      "abstract": {
        "value": "Game theory has grown into a major field over the past few decades, and poker has long served as one of its key case studies. \nGame-Theory-Optimal (GTO) provides strategies to avoid loss in poker, but pure GTO does not guarantee maximum profit.\nTo this end, we aim to develop a model that outperforms GTO strategies to maximize profit in No Limit Hold’em, in heads-up (two-player) and multi-way (more than two-player) situations.\nOur model finds the GTO foundation and goes further to exploit opponents.  \nThe model first navigates toward many simulated poker hands against itself and keeps adjusting its decisions until no action can reliably beat it, creating a strong baseline that is close to the theoretical best strategy. \nThen, it adapts by observing opponent behavior and adjusting its strategy to capture extra value accordingly.\nOur results indicate that Monte-Carlo Counterfactual Regret Minimization (CFR) performs best in heads-up situations and CFR remains the strongest method in most multi-way situations.\nBy combining the defensive strength of GTO with real-time exploitation, our approach aims to show how poker agents can move from merely not losing to consistently winning against diverse opponents."
      },
      "pdf": {
        "value": "/pdf/df059b620dd89f367370d173e116b6632b228cec.pdf"
      },
      "supplementary_material": {
        "value": "/attachment/9acbe0122f7b2ee4b1972a98879908a375ca8336.zip"
      },
      "venue": {
        "value": "Submitted to Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference/Rejected_Submission"
      },
      "_bibtex": {
        "value": "@misc{\nanonymous2025beyond,\ntitle={Beyond Game Theory Optimal: Profit-Maximizing Poker Agents for No-Limit Hold{\\textquoteright}em},\nauthor={Anonymous},\nyear={2025},\nurl={https://openreview.net/forum?id=Xh0s29VtbH}\n}"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757873929090,
    "odate": 1758112145415,
    "mdate": 1759960939058,
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission163/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "74EZ1NRvKM",
    "forum": "Xh0s29VtbH",
    "replyto": "Xh0s29VtbH",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "The paper has significant technical weaknesses, primarily due to its reliance on a simplistic heuristic 'GTO-proxy' rather than actual GTO solutions for evaluation. The synthetic state generation abstracts away much of the complexity of real poker, omitting crucial elements such as position, stack sizes, betting history, and opponent modeling. Evaluation metrics only measure similarity to the proxy, not true game-theoretic optimality or profit maximization. While the paper is generally well-written and organized, there are issues with precision in its claims, particularly in the abstract. The significance and impact are limited by the lack of novelty in problem formulation and the use of synthetic rather than real poker scenarios. The originality is lacking, as the algorithms and comparison framework are well-established, and the main contribution is a systematic comparison on synthetic data. Reproducibility is reasonable, but the reliance on a simple proxy reduces the value of reproducing the results. The limitations section is present but does not fully address the impact of the abstractions. Related work is covered, but the paper does not sufficiently engage with major advances in poker AI. Major concerns include unsupported claims about outperforming GTO, oversimplified abstractions, an inadequate evaluation framework, lack of advancement beyond established results, and no comparison to real solvers or data. Overall, the paper is competently executed within its limited scope but does not provide meaningful insights or sufficient contribution for a high-standard conference."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 2
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 2
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission163/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775983857,
    "mdate": 1760632183729,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission163/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]