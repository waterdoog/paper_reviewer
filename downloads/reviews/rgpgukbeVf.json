[
  {
    "id": "rgpgukbeVf",
    "forum": "rgpgukbeVf",
    "content": {
      "title": {
        "value": "MechSci: Scaling Clinical Science via Mechanistic Interpretability of Multimodal Medical Foundation Models"
      },
      "keywords": {
        "value": [
          "mechanistic interpretability",
          "sparse autoencoders",
          "medical foundation models",
          "hypothesis generation",
          "clinical discovery",
          "imaging biomarkers"
        ]
      },
      "TLDR": {
        "value": "Using mechanistic interpretability we generate thousands of highly prognostic, testable clinical hypotheses (as manuscripts like the one submitted) by mapping foundation model embeddings to human-readable features with LLMs, scaling clinical science."
      },
      "abstract": {
        "value": "Large, multimodal medical datasets harbor complex, latent structures that hold immense potential for scientific discovery. While foundation models excel at extracting predictive signals from such data, their inherent opacity limits their use as tools for generating new scientific knowledge. This work introduces a fully automated pipeline to uncover novel scientific knowledge by transforming the latent representations of medical foundation models into sparse, human-interpretable concepts. We employ Matryoshka Top-K Sparse Autoencoders (SAEs) to decompose dense feature vectors from a 3D CT imaging foundation model into a sparse basis of learned concepts. An automated interpretation module then uses a large language model to assign a semantic, clinical description to each discovered concept. Finally, the system systematically evaluates each concept for its prognostic value across a range of clinical outcomes, generating testable hypotheses. This entire process, from concept discovery to the generation of this manuscript, is automated. As a proof-of-concept, we present a detailed analysis of one such automatically generated hypothesis: a novel imaging biomarker, image_Concept_66, which LLMs concluded to represent \"abnormal soft tissue density and stranding in abdominal fat.\" This feature is shown to be a strong predictor for the future onset of skin cancer (cancer_skin), with an odds ratio of 3.7 (p < 0.001), significantly outperforming clinical risk factors such as patient age, sex, race and BMI and smoking status. This work demonstrates a scalable, end-to-end system that transforms AI from a predictive tool into an engine for generating interpretable and clinically valuable scientific hypotheses."
      },
      "pdf": {
        "value": "/pdf/ff056083f9748a1858ee5e2ad91be0f7f63bfefa.pdf"
      },
      "supplementary_material": {
        "value": "/attachment/03cdd7d57dfce7f37ab1c5fc9601964dbdb76425.pdf"
      },
      "venue": {
        "value": "Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference"
      },
      "_bibtex": {
        "value": "@inproceedings{\nholland2025mechsci,\ntitle={MechSci: Scaling Clinical Science via Mechanistic Interpretability of Multimodal Medical Foundation Models},\nauthor={Robbie Holland and Ashwin Kumar and Eduardo Pontes Reis and Akshay S Chaudhari and Sergios Gatidis},\nbooktitle={Open Conference of AI Agents for Science 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rgpgukbeVf}\n}"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/-/Desk_Rejected_Submission",
      "Agents4Science/2025/Conference/-/Edit",
      "Agents4Science/2025/Conference/Submission278/-/Camera_Ready"
    ],
    "cdate": 1758009549059,
    "pdate": 1759960944143,
    "odate": 1758112145415,
    "mdate": 1765061635780,
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission278/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "n6FhTMu4yn",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Inconsistent definition and reporting of the odds ratio for image_Concept_66 (binary presence vs per-standard-deviation) across Section 3.2.2, Table 1 (page 6), and Table 2 (page 7).\n- Implausible p-value reporting (\"p=0.0\"); should provide an exact p-value or threshold (e.g., p < 1e-X) and state whether it is adjusted for multiplicity.\n- Internal inconsistency in Table 1 (page 6): feature prevalence 7.7% (64/831) and precision 60.9% imply few predicted positives, which is incompatible with the reported specificity of 37.5%. Calculations appear incorrect or thresholds mismatched.\n- Multiple testing correction is stated but unspecified (no method, alpha/FDR, or adjusted p/q-values reported) despite testing 34,047 hypotheses (Section 2.5).\n- Outcome modeling uses logistic associations over a 0.5â€“7.5-year window without handling censoring or variable follow-up; survival analysis would be more appropriate.\n- Unclear data splitting for hypothesis selection; potential test-set leakage if selection/ranking used test statistics (Section 2.5/3.2).\n- Comparisons to established risk factors rely on univariate ORs and potentially mix binary vs per-std scales; no multivariable adjustment to address confounding.\n- Key experimental and reproducibility details (optimizer, learning rate, batch size, epochs, compute resources) are not provided in Methods, despite checklist claims to the contrary.\n- Definition of \"alive features\" and precise SAE training/evaluation protocols are insufficiently specified to assess fairness and reproducibility.\n- External validation is not performed; generalizability remains untested."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776754161,
    "mdate": 1760639992708,
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "d2M5j5Ks98",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents MechSci, an automated pipeline for extracting interpretable concepts from medical foundation models using sparse autoencoders (SAEs) to generate scientific hypotheses. The technical approach is sound, leveraging Matryoshka Top-K SAEs to decompose dense CT image embeddings into sparse, interpretable features. The methodology is well-designed, with clear stages and appropriate statistical analysis. The paper is well-written, clearly structured, and provides good methodological detail, aiding reproducibility. The concept of automated scientific discovery from foundation models is potentially impactful and original, with end-to-end automation representing an interesting advance.\n\nHowever, there are significant concerns: the claimed odds ratio for the discovered biomarker is unusually high, the biological plausibility of the finding is questionable, and the single-center validation limits generalizability. Details on multiple testing correction are insufficient, and the automated interpretation may generate spurious correlations. The clinical significance of the main finding is questionable without external validation and mechanistic understanding. While the technical pipeline is impressive, the specific medical claim requires substantial additional validation before being considered clinically relevant."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775539916,
    "mdate": 1760632216696,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "W9j4nIbnPe",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "decision": {
        "value": "Accept"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! Congratualations on the acceptance! Please see the reviews below for feedback."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759948893479,
    "mdate": 1760632291684,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "TGAJucfPf8",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "title": {
        "value": "Human Review"
      },
      "summary": {
        "value": "MechSci presents an automated pipeline for scientific discovery that uses Sparse Autoencoders (SAEs) to decompose medical foundation model representations into interpretable concepts, automatically labels them with LLMs, and tests associations with clinical outcomes. The system applies Matryoshka Top-K SAEs to CT imaging embeddings from a dataset of Stanford patients. As proof-of-concept, the paper highlights one discovered imaging biomarker, \"abnormal soft tissue density in abdominal fat\" (image_Concept_66), that predicts skin cancer with an odds ratio of 3.7, outperforming age and BMI."
      },
      "strengths_and_weaknesses": {
        "value": "Strengths:\n- The key methodological innovation is using Matryoshka Top-K SAEs, which learn nested, hierarchical feature sets rather than flat dictionaries. This provides features at multiple granularity levels and improves the Pareto frontier for reconstruction\n- The technical approach is sound. SAEs successfully decompose dense 1024-dimensional CT embeddings into sparse, interpretable concepts while maintaining predictive performance on downstream tasks. The automated interpretation module with validation on held-out samples provides quality control.\n- The paper clearly explains the four-stage pipeline with appropriate technical detail.\n\nWeaknesses:\n- The established risk factors comparison (Table 2) lacks explanation. How were these specific risk factors selected? Were they chosen by domain experts, from literature, or post-hoc? This is critical for validating the claim that the discovered feature \"outperforms\" established factors when the comparison may not include the most relevant clinical predictors.\n- There is clinical validation of the auto-generated interpretation. Was \"abnormal soft tissue density and stranding in abdominal fat\" verified by radiologists as medically sensible? Do pathologists already look for this feature when evaluating skin cancer risk? Without expert validation, we cannot assess whether the pipeline discovered something new or standard.\n- Figure 5 and Table 2 present redundant information (the same odds ratios appear in both).\n- Legends in Figures 3 and 6 are unclear about what \"false\" and the bracketed numbers represent. The notation needs explicit explanation.\n- The two acknowledged limitations - single-center data and correlation versus causation - are critical and undermine the scientific discovery claims. The biomarker might proxy for confounders (e.g., specific treatment patterns at Stanford). Testing only correlations means we cannot distinguish true biological relationships from statistical associations.\n- The pipeline tests individual features in isolation but doesn't explore feature combinations. Clinical prediction often benefits from multiple biomarkers.\n- There is no mechanism to check whether the \"discovered\" hypotheses are already known in medical literature. The pipeline could be rediscovering established findings, wasting resources on validation studies for non-novel results.\n- The appendix is missing"
      },
      "quality": {
        "value": 3
      },
      "clarity": {
        "value": 3
      },
      "significance": {
        "value": 3
      },
      "originality": {
        "value": 3
      },
      "questions": {
        "value": "See weaknessess"
      },
      "limitations": {
        "value": "See weaknessess"
      },
      "overall": {
        "value": 5
      },
      "confidence": {
        "value": 4
      },
      "ethical_concerns": {
        "value": "No"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759191040416,
    "mdate": 1760632217039,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_kzx3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission278/Reviewer_kzx3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "CNgRxE2Cm6",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents \"MechSci,\" a fully automated pipeline for scientific discovery using medical data, integrating 3D CT scan foundation models, Matryoshka Top-K Sparse Autoencoders (SAEs), and large language models (LLMs) for concept interpretation. The system identifies a novel imaging biomarker predictive of skin cancer and even generated the manuscript for the paper. The review praises the work as technically sound, highly original, and potentially transformative, with excellent quality, clarity, and significance. The methodology is robust, results are compelling, and the paper is well-written. Constructive feedback includes questions about the robustness of LLM-based interpretation, handling of confounding factors, and clarification on the extent of human post-processing in manuscript generation. The reviewer concludes that this is a landmark, visionary paper and recommends strong accept without hesitation."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 6
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 6
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775539717,
    "mdate": 1760632216818,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "AQnwTq7EVi",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "desk_reject_comments": {
        "value": "Paper does not respect the conference requirements (e.g., Checklists and Formatting issues)"
      },
      "title": {
        "value": "Submission Desk Rejected by Program Chairs"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Desk_Rejection",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Desk_Rejection",
    "cdate": 1758130190556,
    "mdate": 1765059676757,
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "7ndeNG9LgO",
    "forum": "rgpgukbeVf",
    "replyto": "rgpgukbeVf",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "This paper introduces an end-to-end, largely automated pipeline for scientific discovery from multimodal clinical data, focusing on mechanistic interpretability of medical foundation models. The approach decomposes dense 3D CT embeddings using Matryoshka Top-K SAEs, auto-interprets features with an LLM, screens features for association with 39 clinical outcomes, and enables agentic manuscript generation via a web UI. A case study highlights a feature associated with future skin cancer (odds ratio ~3.7, p < 0.001).\n\nStrengths include the ambitious framing, methodological novelty, evidence of representational quality, scalable hypothesis generation, and a generally clear and transparent presentation. However, there are significant concerns:\n\n1. Multiple testing correction is insufficiently detailed, with no adjusted p-values or correction method specified, raising false discovery risks.\n2. Confounding and model specification are inadequately addressed; claims of outperforming established risk factors are not justified without multivariable or survival analysis, and important confounders are unadjusted.\n3. Interpretability validation is weak, lacking independent radiologist adjudication and standardized metrics.\n4. Clinical utility is unclear due to low specificity, missing calibration, and lack of decision-curve analysis.\n5. Reproducibility is limited by missing implementation details and unclear data/code availability.\n6. No external validation is provided, undermining claims of generalizability.\n7. Related work coverage is incomplete, with insufficient empirical comparison to prior concept-based interpretability methods.\n8. Reporting clarity issues exist regarding feature definitions, patient splits, outcome ascertainment, and thresholding.\n\nActionable suggestions include providing full multiple testing methodology, using multivariable and survival models, adding external validation, including human expert adjudication, expanding methodological details, improving related work coverage, and tempering claims until further validation is achieved.\n\nOverall, while the direction and systems contribution are promising, the current version falls short on statistical rigor, interpretability validation, reproducibility, and external validation. The verdict is a borderline reject due to these shortcomings, despite the innovative vision."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission278/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775539393,
    "mdate": 1760632216929,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission278/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]