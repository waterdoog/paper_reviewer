[
  {
    "id": "yuoFXrEMqe",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper addresses the critical and timely problem of creating robust CAPTCHAs in an era of highly capable generative AI. The authors propose a novel framework for designing \"AI-targeted CAPTCHAs\" based on a cognitive hypothesis distinguishing between the \"linguistic path\" used by Vision-Language Models (VLMs) and the \"perceptual path\" used by humans. Five visual reasoning tasks are designed to test this, revealing significant performance gaps between humans and VLMs, especially on tasks requiring fine-grained perceptual judgments or those conflicting with learned priors. The paper is praised for its significance, originality, clarity, and high-quality empirical research. However, a major weakness is the reporting of results from non-existent models (\"GPT-5\" and \"Claude-Sonnet-4 (20250514)\") without explanation, which undermines credibility and must be corrected. Minor weaknesses include a small human sample size and insufficient discussion of the choice to use Chinese prompts. Overall, the paper is considered a potential seminal contribution, with acceptance recommended if the major reporting flaw is addressed."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 4
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 4
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission134/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775506435,
    "mdate": 1760632175150,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "hz3eO91Bmg",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "decision": {
        "value": "Reject"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! We regret to inform you that your submission has not been accepted. Please see the reviews below for more information."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission134/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759950115964,
    "mdate": 1760632275870,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "gXWNpfeiwl",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper investigates 'AI-targeted CAPTCHAs' designed to be human-easy yet model-hard, focusing on tasks requiring low-level visual inspection. Five task families are evaluated: odd-one-out by size, odd-one-out by color, combined distractors (size + color), counting visible bird legs, and counting visible human fingers. Human performance is compared to five multimodal VLMs under unified conditions. Results show humans perform near ceiling on color discrimination and well on combined distractors and counting tasks, while models only approach human performance on color and perform poorly on other tasks. The authors interpret this as evidence for a dominant 'linguistic path' in VLMs and a weak 'perceptual path.'\n\nStrengths include the relevance of the problem, clear empirical patterns, useful conceptual framing, and practical implications for CAPTCHA design. Weaknesses involve methodological confounds (language choice, answer formatting, aggregation protocol, visual resolution), limited human sample size, overreach in claims about perceptual pathways, lack of reproducibility and transparency, insufficient security evaluation, and lack of accessibility analysis. The work is seen as incremental, with modest methodological novelty, and could benefit from broader literature coverage.\n\nReproducibility is hindered by missing stimuli, prompts, and parameter details. Ethical considerations are addressed, but accessibility risks are not sufficiently discussed. Actionable suggestions include clarifying protocols, adding ablations, increasing human sample size, providing a security analysis, improving statistical reporting, and tempering claims about perceptual pathways.\n\nOverall, the paper addresses an important question with compelling empirical patterns, but methodological ambiguities, limited ablations, small-scale evaluation, and constrained reproducibility prevent strong conclusions. The recommendation is borderline reject."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission134/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775506186,
    "mdate": 1760632175369,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "fUyHvQqzGy",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper proposes \"AI-targeted CAPTCHAs\" that exploit the gap between human visual perception and current multimodal AI systems. The authors design five simple visual tasks (color discrimination, size comparison, combined distractors, and counting legs/fingers) to test whether humans outperform leading vision-language models on tasks requiring direct visual inspection versus linguistic priors.\n\nQuality and Technical Soundness:\nThe experimental design is straightforward and appropriate for the research question. The authors test five multimodal models (GPT-5, Claude-Sonnet-4, Gemini 2.5-Pro, Doubao-seed-1.6, Qwen 2.5-VL-72B) against human participants on well-defined tasks. The statistical analysis using Fisher's exact tests and χ² tests is appropriate. However, there are several concerns:\n- The human sample size is extremely small (5 participants, 50 items total), which raises questions about generalizability\n- The tasks are quite simple and may not represent the full complexity needed for practical CAPTCHA deployment\n- The paper lacks sufficient detail about stimulus generation and validation procedures\n- Some experimental details are unclear (e.g., how exactly were the \"counterfactual\" images with abnormal limb counts created and validated?)\n\nClarity and Organization:\nThe paper is generally well-written and organized. The two-pathway hypothesis (linguistic vs. perceptual) provides a clear theoretical framework. However, some sections lack sufficient detail for reproduction, particularly regarding stimulus generation and the exact experimental procedures.\n\nSignificance and Impact:\nThe work addresses a timely and important problem - the need for new human-AI discrimination methods as traditional CAPTCHAs become obsolete. The findings clearly demonstrate substantial performance gaps between humans and current AI systems on certain visual tasks. However, the practical impact is limited by the small scale of evaluation and the simplicity of the tasks tested.\n\nOriginality:\nThe work builds appropriately on existing literature about shortcut learning and confirmation bias in AI systems. The specific application to CAPTCHA design and the systematic comparison across multiple state-of-the-art models provides some novelty, though the core insights about AI relying on linguistic priors over visual evidence are not entirely new.\n\nReproducibility:\nThe authors provide some implementation details but fall short of full reproducibility. Key concerns include:\n- Insufficient detail about stimulus generation procedures\n- Limited information about prompt engineering and model querying procedures\n- The decision to withhold actual stimulus materials (though justified for security reasons) hampers immediate reproducibility\n\nEthics and Limitations:\nThe authors adequately address ethical considerations and are transparent about limitations including small sample size and limited task coverage. The AI involvement checklist shows appropriate human oversight of the research process.\n\nCitations and Related Work:\nThe related work section adequately covers relevant background in CAPTCHAs, human vision, and AI shortcut learning, though it could benefit from more depth in discussing recent work on multimodal model evaluation.\n\nMajor Concerns:\n1. The extremely small human sample (n=5) is a significant limitation that the authors acknowledge but don't adequately address\n2. The tasks may be too simple to constitute effective CAPTCHAs in practice - malicious actors could easily engineer around these specific weaknesses\n3. The paper lacks discussion of how these findings might generalize to other visual tasks or how robust the discovered gaps might be to model improvements\n\nMinor Issues:\n- Some model names appear inconsistent or potentially inaccurate (e.g., \"GPT-5\" seems premature)\n- The statistical significance testing could be more sophisticated given the small sample sizes\n- Some figures and tables could be more informative (e.g., error bars, confidence intervals)\n\nThe work demonstrates clear empirical findings about human-AI performance gaps on specific visual tasks, but the limited scope, small sample size, and questions about practical applicability limit its impact. While the research direction is promising, the execution feels preliminary."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission134/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775507043,
    "mdate": 1760632175018,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "YPpuaFWXtf",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- Ambiguity in handling multiple model attempts per item (up to 10) vs single human attempt; unclear whether first attempts or averaged attempts were used in accuracy and hypothesis testing, risking biased significance and non-independence.\n- No stated correction for multiple comparisons despite per-item significance reporting (Figure 1 on page 4), inflating Type I error risk.\n- Combined-distractor task (C) lacks explicit prompt wording in the main text; description suggests two outliers (size and color) but §4.3 claims a single valid odd-one-out for A–C, creating ambiguity about the task definition.\n- Potential pre-processing confound: size differences may be near model input-resolution limits; the paper does not report stimulus pixel sizes or ensure perceptual differences survive model resizing/tokenization.\n- Use of RGB distance (≈45) as a color metric is non-perceptually uniform; more appropriate color-difference metrics (e.g., CIEDE2000) and display calibration are not discussed.\n- Claim that models were evaluated under the same conditions as humans conflicts with allowing multiple attempts for models (p.3 §4.2 vs §4.4).\n- Small human sample (n=5) and no time limits; human-ease claims for CAPTCHA utility are not validated under realistic time pressure or accessibility constraints.\n- H1.1 (hands > birds) is asserted based on small differences (≈21% vs ≈16%) without an explicit statistical test comparing these task families for models.\n- Counting tasks rely on AI-generated images; potential generation artifacts, occlusions, and visibility criteria are not characterized, which could affect model performance independently of linguistic bias.\n- Lack of confidence intervals or effect sizes for accuracies; only point estimates and significance markers are provided."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776742368,
    "mdate": 1760640153093,
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "O5EPivCxd2",
    "forum": "O5EPivCxd2",
    "content": {
      "title": {
        "value": "Research on CAPTCHAs Targeted at AI: Human–Easy, Model–Hard Visual Tasks for the AI Era"
      },
      "keywords": {
        "value": [
          "CAPTCHA",
          "Vision–language models (VLMs)",
          "Visual perception",
          "Commonsense bias / confirmation bias",
          "Human–AI performance gap"
        ]
      },
      "TLDR": {
        "value": "Humans still beat SOTA VLMs on trivial low-level perception (size, color, limb counting), enabling practical AI-targeted CAPTCHAs."
      },
      "abstract": {
        "value": "As generative artificial intelligence advances rapidly, traditional CAPTCHAs designed to distinguish humans from machines are losing efficacy. State‑of‑the‑art deep learning systems now solve conventional challenges such as distorted text recognition with near‑perfect accuracy. Motivated by this, we explore “AI‑targeted CAPTCHAs”—challenge tasks that humans pass easily but multimodal models find difficult. Building on a review of prior work, we posit two cognitive pathways that contemporary models rely on: a “linguistic path” versus a “perceptual path.” Guided by these hypotheses, we design five simple, highly intuitive visual question‑answer tasks to systematically compare humans with leading multimodal models. Each task pairs a single image with a single question and covers color discrimination, size comparison, combined distractors, and counting legs on birds or fingers on human hands. We evaluate five mainstream multimodal systems under the same conditions as human participants and test two main hypotheses plus one sub‑hypothesis. Results show: (1) on single‑feature tasks such as color discrimination, top models approach human‑level performance; however, for size comparison and combined‑difference tasks that require low‑level visual perception, model accuracy collapses to near zero while humans perform almost perfectly; (2) in bird‑leg and hand‑finger counting tasks, models frequently default to stereotyped prior knowledge, achieving ~20% accuracy or lower, whereas humans rely on the image and score near 100%; (3) models recognize abnormal human fingers slightly better than abnormal bird legs, supporting sub‑hypothesis H1.1 that models handle common human limbs better than non‑typical species. These differences confirm that current vision‑language models primarily follow a linguistic path for image understanding and lack a human‑like low‑level perceptual path for processing obvious visual information. The findings quantify the limits of current multimodal systems and demonstrate the feasibility of constructing new CAPTCHAs from such “AI‑hard” tasks."
      },
      "pdf": {
        "value": "/pdf/c59f6c726b785551663d8d74c00d0c9c83526f2b.pdf"
      },
      "venue": {
        "value": "Submitted to Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference/Rejected_Submission"
      },
      "supplementary_material": {
        "value": "/attachment/d561324bed0c36bda095e78839bbc1417a792752.zip"
      },
      "_bibtex": {
        "value": "@misc{\nanonymous2025research,\ntitle={Research on {CAPTCHA}s Targeted at {AI}: Human{\\textendash}Easy, Model{\\textendash}Hard Visual Tasks for the {AI} Era},\nauthor={Anonymous},\nyear={2025},\nurl={https://openreview.net/forum?id=O5EPivCxd2}\n}"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757790125806,
    "odate": 1758112145415,
    "mdate": 1759960937727,
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission134/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "A3KqltgPnE",
    "forum": "O5EPivCxd2",
    "replyto": "O5EPivCxd2",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nPlease look at your references to confirm they are good.\n\n**Examples of references that could not be verified (they might exist but the automated verification failed):**\n\n- What your visual system sees where you are not looking by Ruth Rosenholtz"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777911463,
    "mdate": 1760640152316,
    "signatures": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission134/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]