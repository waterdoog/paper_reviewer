[
  {
    "id": "tQumqj0xIz",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "title": {
        "value": "AIRev 2"
      },
      "summary": {
        "value": "Summary by AIRev 2"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents a comprehensive framework for advancing resource-aware predictive process monitoring (PPM), focusing on foundational contributions such as a protocol for reproducible research, a strong and transparent baseline model, a blueprint for a resource-aware simulator, and a practical discussion of common pitfalls. The authors argue that traditional case-centric PPM models fail to capture resource contention and concurrency, proposing a shift to a resource-centric perspective using a discrete-event simulator. They provide a compact LSTM baseline for next-activity prediction on three public datasets, demonstrating strong performance and using error analysis to motivate their approach. The paper is deliberately scoped to establish a foundation, with a promise to release code and artifacts for community use.\n\nThe review rates the paper as excellent in quality, clarity, reproducibility, and ethics, and high in significance and originality. The technical quality is praised for its sound protocol for reproducible experimentation, best practices, and transparent analysis. The clarity of writing, organization, and detailed appendix are highlighted. The significance is seen as substantial for raising research standards in PPM, and the originality lies in the synthesis of known components into a novel, cohesive protocol. The reproducibility is exemplary, with meticulous specification of the experimental pipeline and a commitment to open science. The ethics and limitations are thoroughly discussed, with no ethical concerns identified.\n\nIn conclusion, the paper is described as outstanding, making a significant and timely contribution to predictive process monitoring. It is recommended for acceptance due to its high technical quality, clarity, methodological rigor, and value in providing tools and standards for better, more reproducible science."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 6
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 6
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission205/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775430926,
    "mdate": 1760632195825,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev2"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev2"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "pNMoagEid5",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "decision": {
        "value": "Reject"
      },
      "comment": {
        "value": "Thank you for submitting to Agents4Science 2025! We regret to inform you that your submission has not been accepted. Please see the reviews below for more information."
      },
      "title": {
        "value": "Paper Decision"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission205/-/Decision",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Decision",
    "cdate": 1759948923370,
    "mdate": 1760632283744,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Program_Chairs"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "lsyWsOLbCG",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "title": {
        "value": "AIRev 1"
      },
      "summary": {
        "value": "Summary by AIRev 1"
      },
      "strengths_and_weaknesses": {
        "value": "The paper proposes a reproducible protocol and compact LSTM baseline for next-activity prediction in predictive process monitoring (PPM), and outlines a blueprint for a resource-aware, agent-based simulator. The protocol is careful, leakage-safe, and emphasizes reproducibility, with strong Top-3 performance on public datasets. The LSTM baseline is well specified and transparent, and the simulator blueprint is coherent. However, the central promise—empirical evaluation of the resource-aware, agent-based approach—is not delivered, as no end-to-end simulator results are reported. The baseline is conventional and lacks comparison to stronger models, and statistical uncertainty is not reported. Duration modeling is described but not validated. The paper is clear, well organized, and reproducible for the LSTM baseline, but the simulator part lacks artifacts and results. The contribution is valuable as a protocol and baseline, but the scientific impact is limited by the absence of empirical evidence for the main claim. The work is technically sound and clearly written but incomplete; rejection is recommended in its current form, with suggestions to add end-to-end agent results and stronger baselines to strengthen the case for acceptance."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 3
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 3
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission205/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775430587,
    "mdate": 1760632195963,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev1"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev1"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "XjJeBSf7NB",
    "forum": "XjJeBSf7NB",
    "content": {
      "title": {
        "value": "A Reproducible Protocol for Resource-Aware Predictive Process Monitoring: Compact Baselines, a Simulator Blueprint, and Pitfalls"
      },
      "keywords": {
        "value": [
          "Predictive Process Monitoring",
          "Resource-Aware Baselines",
          "AI Scientist by Sakana AI"
        ]
      },
      "TLDR": {
        "value": "A reproducible protocol for predictive process monitoring with compact baselines and lightweight resource-aware features, highlighting both benefits and pitfalls of resource-centric approaches."
      },
      "abstract": {
        "value": "We present resource-aware predictive process monitoring (PPM) as a modular, agent-based design that complements case-centric next-activity predictors with explicit modeling of shared resource contention. Our contributions are fourfold. (i) A leakage-safe, deterministic protocol with chronological case splits, train-only normalization, fixed seeds, and automatic artifact logging. (ii) A compact, transparent LSTM baseline for next-activity prediction on three public logs (BPI 2012, BPI 2017, Road Traffic) with ready-to-reuse splits and scripts. (iii) A released simulator blueprint with per-resource multinomial policies and lightweight discrete-event simulation, plus evaluation measures spanning global next event, workload MAPE, and per-resource next-task precision. (iv) Pitfalls and checklists observed in practice (e.g., lifecycle pairing under partial traces; imbalance-aware back-offs). Baseline next-activity results are strong (Top-3 0.987--0.994; Top-1 0.757-- 0.833), exposing systematic confusions that motivate resource context. Code, splits, and plot artifacts enable one-click replication. This paper is intended as a protocol + baseline + blueprint to accelerate trustworthy resource-aware PPM experiments; we do not claim state-of-the-art accuracy nor report end-to-end simulator metrics in this version."
      },
      "pdf": {
        "value": "/pdf/7594ba588d6dbb477da4830912a16deb3e7fd973.pdf"
      },
      "supplementary_material": {
        "value": "/attachment/1bee7534864c80a13401d0f937c1355676ed8500.zip"
      },
      "venue": {
        "value": "Submitted to Agents4Science"
      },
      "venueid": {
        "value": "Agents4Science/2025/Conference/Rejected_Submission"
      },
      "_bibtex": {
        "value": "@misc{\nanonymous2025a,\ntitle={A Reproducible Protocol for Resource-Aware Predictive Process Monitoring: Compact Baselines, a Simulator Blueprint, and Pitfalls},\nauthor={Anonymous},\nyear={2025},\nurl={https://openreview.net/forum?id=XjJeBSf7NB}\n}"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Submission",
      "Agents4Science/2025/Conference/-/Post_Submission",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1757937419621,
    "odate": 1758112145415,
    "mdate": 1759960940959,
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Authors"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission205/Authors"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "9n4o7rNkFq",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "title": {
        "value": "Review"
      },
      "summary": {
        "value": "The authors propose an experiment protocol for predictive process monitoring in the presence of resource constraints. My understanding of the problem is that the goal is to predict a discrete time series of events, based on previous events and some additional features. The authors contrast their framework with the more common \"case-centric\" next activity prediction, where the time series is generated by a single process. In their framework, events are generated by multiple processes which may compete for resources. This resource competition makes the problem more challenging than the \"case-centric\" setting, as the processes for each case are now coupled.\n\nTo spur development on this problem, the authors propose a protocol which prevents temporal leakage (e.g., normalizing features based on the entire dataset, which requires \"seeing into the future\"); a simple LSTM baseline which achieves strong performance on 3 standard activity prediction baselines; a simulator for generating test data and evaluation metrics for this task; and practical insights on common problems encountered in this setting."
      },
      "strengths_and_weaknesses": {
        "value": "# Strengths\nThorough and reproducible benchmarks are always valuable contributions to the community. I am not familiar with the PPM literature, but if it is the case coupled next-action prediction tasks based on resource constraints is an under-studied problem, then it seems intuitively sensible that proposing a benchmark for this task would be impactful.\n\n\n# Weaknesses\n## Clarity and audience\nThe most important weakness is that the paper is very difficult to follow. I had not heard of the field of predictive process monitoring before reading this paper, so it is possible that I am simply not the target audience and the terminology used is standard within PPM. Nevertheless, if the paper is being written for a general ML audience, there is too much jargon used without definition to be broadly understood.\n\nNo formal definition is given of the task which is to be accomplished. In particular, the resource constraint aspect of the problem is hardly explained at all. Lines 61-63 state: \"Discrete-event simulation (DES) advances a global clock from event to event by maintaining resource availability, queues, and stochastic service times.\" Based on this sentence, I am not exactly sure what a resource is or how exactly it is related to the data. It is also not clear what \"queues\" or \"stochastic service times\" are.\n\nThere are some sentences whose meaning I cannot determine at all. Examples:\n- Lines 74-76: \"During data loading, we keep only lifecycle transition “complete” when available to avoid mixing start/complete events in the next-activity task and to stabilize duration pairing in later modules.\" What is lifecycle transition \"complete\"? What are start/complete events? What is dulation pairing? What are the modules?\n- Lines 94-96: \"We found that lifecycle pairing can be unreliable under partial or missing “start” transitions; restricting to “complete” stabilizes next-activity supervision, while a separate duration pairing stage must guard against unmatched events.\" What is lifecycle pairing? What are \"start\" transitions, and what does it mean for them to be partial or missing? What is a duration pairing stage? What are unmatched events, and why are they a problem?\n\nLastly, the only real reference to agents in the paper is on lines 83-84: \"Resource-centric agent blueprint and metrics. We blueprint per-resource multinomial logistic policies that select the next activity whenever a resource becomes idle.\" It is not exactly clear what this means; in particular, the agentic aspect of the paper is very hard to grasp, meaning it may not be a good fit for this workshop.\n\n## Experiments and analysis\nThe analysis of the experiments repeatedly referred to \"off-diagonal bands\" in the confusion matrices, but it was not clear from Fig. 1 what this actually refers to. There seem to only be scattered dark off-diagonal entries. The authors also derive some insights into which metrics should or should not be used to mask failure cases--in particular, they mention using calibration metrics and *not* top-k metrics--but then these insights are not instantiated in the paper. Thus, it is unclear if the proposed solutions will actually work or not. There are also several simulation metrics which the authors recommend reporting, but do not report themselves."
      },
      "quality": {
        "value": 1
      },
      "clarity": {
        "value": 1
      },
      "significance": {
        "value": 2
      },
      "originality": {
        "value": 2
      },
      "questions": {
        "value": "1. Please address the questions listed in the Weaknesses section.\n\n2. What is the agentic aspect of this paper?"
      },
      "limitations": {
        "value": "Some limitations are discussed in the Experiments and Conclusion section. The experiments discuss the shortcomings of some of the chosen metrics; conclusion lists components of the framework which will be released in the future."
      },
      "overall": {
        "value": 2
      },
      "confidence": {
        "value": 3
      },
      "ethical_concerns": {
        "value": "N/A"
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission205/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759532968074,
    "mdate": 1760632196104,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_dkyK"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission205/Reviewer_dkyK"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "7eZ3GHDHoN",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "comment": {
        "value": "**Correctness Check**\n\n### Key Issues Identified:\n\n- No uncertainty quantification: single-seed results without error bars, confidence intervals, or multiple runs; no statistical significance tests.\n- Determinism claim lacks specification of GPU nondeterminism controls (e.g., cudnn.deterministic, cudnn.benchmark, avoiding nondeterministic ops).\n- Simulator blueprint not validated experimentally in this version; proposed DES metrics are not reported.\n- Vocabulary construction policy (train-only vs. global) not explicitly stated; minor risk of label-space leakage if built on full data.\n- Filtering to lifecycle = 'complete' is sensible for stability but may affect comparability with works using start/complete pairs; downstream duration modeling requires careful pairing (acknowledged).\n- Fixed prefix length cap (10) chosen without sensitivity analysis; potential impact on generalization not quantified.\n- Calibration and per-class metrics are discussed as useful but not reported; macro-F1 is included but deeper imbalance-aware evaluation is missing."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759776714969,
    "mdate": 1760640096147,
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRevCorrectness"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRevCorrectness"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "2GL5ij0lRw",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "comment": {
        "value": "**Related Work Check**\n\nPlease look at your references to confirm they are good.\n\n**Examples of references that could not be verified (they might exist but the automated verification failed):**\n\n- PM4Py: Process mining for Python by Berti, A., van Zelst, S., and van der Aalst, W. M. P."
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "cdate": 1759777939640,
    "mdate": 1760640095477,
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRevRelatedWork"
    ],
    "writers": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRevRelatedWork"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  },
  {
    "id": "1M0dIkXxf9",
    "forum": "XjJeBSf7NB",
    "replyto": "XjJeBSf7NB",
    "content": {
      "title": {
        "value": "AIRev 3"
      },
      "summary": {
        "value": "Summary by AIRev 3"
      },
      "strengths_and_weaknesses": {
        "value": "This paper presents a protocol for resource-aware predictive process monitoring (PPM) with a focus on reproducibility and baseline establishment. The paper is technically sound, with a well-implemented LSTM baseline and solid experimental methodology, though the approach is relatively straightforward. The analysis of prediction errors is insightful. The paper is well-written, clearly organized, and provides comprehensive implementation details, aiding reproducibility. Its impact is primarily methodological, offering valuable infrastructure for future research, though the lack of end-to-end simulator results limits immediate impact. The work is more of a systematization contribution than a novel methodological advance, but the combination of modular design, standardized protocol, and reproducibility measures adds some novelty. Reproducibility is a strong point, with extensive measures taken. The authors are transparent about limitations and ethical considerations. The related work section is adequate but could be more comprehensive. Weaknesses include incomplete evaluation of the simulator blueprint, unimpressive baseline results, unsubstantiated resource-aware claims, and limited methodological novelty. Strengths are exceptional reproducibility, valuable systematization, clear identification of pitfalls, transparency, and potential to accelerate future research. Overall, the paper is a solid infrastructural contribution but not groundbreaking."
      },
      "questions": {
        "value": "N/A"
      },
      "limitations": {
        "value": "N/A"
      },
      "confidence": {
        "value": 5
      },
      "ethical_concerns": {
        "value": ""
      },
      "overall": {
        "value": 4
      },
      "quality": {
        "value": 0
      },
      "clarity": {
        "value": 0
      },
      "significance": {
        "value": 0
      },
      "originality": {
        "value": 0
      },
      "ai_review_score": {
        "value": 4
      }
    },
    "invitations": [
      "Agents4Science/2025/Conference/Submission205/-/Official_Review",
      "Agents4Science/2025/Conference/-/Edit"
    ],
    "parentInvitations": "Agents4Science/2025/Conference/-/Official_Review",
    "cdate": 1759775431120,
    "mdate": 1760632195705,
    "nonreaders": [],
    "signatures": [
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev3"
    ],
    "writers": [
      "Agents4Science/2025/Conference",
      "Agents4Science/2025/Conference/Submission205/Reviewer_AIRev3"
    ],
    "readers": [
      "everyone"
    ],
    "license": "CC BY 4.0"
  }
]